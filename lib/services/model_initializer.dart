import 'dart:async';
import 'dart:developer' as developer;
import 'dart:io';
import 'package:flutter_gemma/flutter_gemma.dart';
import 'package:get_it/get_it.dart';
import 'package:path_provider/path_provider.dart';
import 'package:path/path.dart' as path;
import 'package:shared_preferences/shared_preferences.dart';

enum InitializationStatus {
  notStarted,
  inProgress,
  completed,
  failed,
  retrying
}

class InitializationResult {
  final bool success;
  final String? error;
  final InitializationStatus status;
  final int attemptNumber;

  const InitializationResult({
    required this.success,
    this.error,
    required this.status,
    required this.attemptNumber,
  });
}

class ModelInitializer {
  static const int maxRetries = 3;
  static const Duration baseDelay = Duration(seconds: 2);
  static const Duration maxDelay = Duration(seconds: 30);
  static const String _crashDetectionKey = 'dyslexic_ai_model_init_in_progress';

  // Removed _gemmaPlugin as we now use static FlutterGemma API

  int _currentAttempt = 0;
  InitializationStatus _status = InitializationStatus.notStarted;
  String? _lastError;

  InitializationStatus get status => _status;
  String? get lastError => _lastError;
  int get currentAttempt => _currentAttempt;

  /// Initialize model with retry logic and exponential backoff
  /// This method should NEVER delete files - it only handles memory initialization
  Future<InitializationResult> initializeModelWithRetry(
      String modelPath) async {
    developer.log('üöÄ Starting model initialization with retry logic...',
        name: 'dyslexic_ai.model_initializer');

    _status = InitializationStatus.inProgress;
    _currentAttempt = 0;
    _lastError = null;

    // Validate file exists before attempting initialization
    final file = File(modelPath);
    if (!file.existsSync()) {
      const error =
          'Model file does not exist - this should not happen after download validation';
      developer.log('‚ùå $error', name: 'dyslexic_ai.model_initializer');
      _status = InitializationStatus.failed;
      _lastError = error;
      return InitializationResult(
        success: false,
        error: error,
        status: _status,
        attemptNumber: 0,
      );
    }

    final fileSize = await file.length();
    developer.log(
        'üìä Initializing model file: ${(fileSize / (1024 * 1024)).toStringAsFixed(1)}MB',
        name: 'dyslexic_ai.model_initializer');

    final prefs = await SharedPreferences.getInstance();
    
    // Always clear GPU cache before initialization to prevent stale cache issues
    // The .bin files in cache reference the original model path, and if that path
    // changes (e.g., after reinstall or cache clear), TFLite will fail to find the file
    developer.log(
        'üßπ Clearing GPU cache before initialization to ensure fresh start...',
        name: 'dyslexic_ai.model_initializer');
    await clearGpuCache();
    
    // Check if we crashed last time (for additional logging/diagnostics)
    if (prefs.getBool(_crashDetectionKey) == true) {
      developer.log(
          '‚ö†Ô∏è DETECTED CRASH: Initialization was interrupted previously.',
          name: 'dyslexic_ai.model_initializer');
    }

    // Set crash marker - if we die after this, next run will know
    await prefs.setBool(_crashDetectionKey, true);

    try {
      // Attempt initialization with retry logic
    for (_currentAttempt = 1;
        _currentAttempt <= maxRetries;
        _currentAttempt++) {
      try {
        developer.log('üîÑ Initialization attempt $_currentAttempt/$maxRetries',
            name: 'dyslexic_ai.model_initializer');

        if (_currentAttempt > 1) {
          _status = InitializationStatus.retrying;
        }

        final success = await _attemptInitialization(modelPath);

        if (success) {
          _status = InitializationStatus.completed;
          developer.log(
              '‚úÖ Model initialization successful on attempt $_currentAttempt',
              name: 'dyslexic_ai.model_initializer');

          return InitializationResult(
            success: true,
            status: _status,
            attemptNumber: _currentAttempt,
          );
        } else {
          _lastError =
              'Model initialization failed on attempt $_currentAttempt';
          developer.log('‚ùå $_lastError', name: 'dyslexic_ai.model_initializer');
        }
      } catch (e) {
        _lastError = 'Initialization attempt $_currentAttempt failed: $e';
        developer.log('‚ùå $_lastError', name: 'dyslexic_ai.model_initializer');
      }

      // Don't delay after the last attempt
      if (_currentAttempt < maxRetries) {
        final delay = _calculateBackoffDelay(_currentAttempt);
        developer.log(
            '‚è≥ Waiting ${delay.inSeconds}s before retry ${_currentAttempt + 1}',
            name: 'dyslexic_ai.model_initializer');
        await Future.delayed(delay);
      }
    }

    // All attempts failed
    _status = InitializationStatus.failed;
    final finalError =
        'Model initialization failed after $maxRetries attempts. Last error: $_lastError';
    developer.log('‚ùå $finalError', name: 'dyslexic_ai.model_initializer');

    // Attempt to clear GPU cache to fix potential corruption for next time
    await clearGpuCache();

    return InitializationResult(
      success: false,
      error: finalError,
      status: _status,
      attemptNumber: _currentAttempt,
    );
  } finally {
      // Clear crash marker - we survived!
      await prefs.setBool(_crashDetectionKey, false);
    }
  }

  /// Clear GPU delegate cache files to resolve corruption issues
  Future<void> clearGpuCache() async {
    try {
      final tempDir = await getTemporaryDirectory();
      developer.log('üßπ Clearing GPU cache in: ${tempDir.path}', 
          name: 'dyslexic_ai.model_initializer');
      
      final dir = Directory(tempDir.path);
      if (await dir.exists()) {
        final List<FileSystemEntity> entities = await dir.list().toList();
        int deletedCount = 0;
        
        for (final entity in entities) {
          if (entity is File) {
            final filename = path.basename(entity.path);
            // Delete .bin files (TFLite cache) and .task files (if any ended up there)
            if (filename.endsWith('.bin') || filename.contains('gemma')) {
               try {
                 await entity.delete();
                 deletedCount++;
               } catch (e) {
                 // Ignore delete errors for locked files
               }
            }
          }
        }
        
        developer.log('‚ú® Deleted $deletedCount cache files', 
            name: 'dyslexic_ai.model_initializer');
      }
    } catch (e) {
      developer.log('‚ö†Ô∏è Error clearing GPU cache: $e', 
          name: 'dyslexic_ai.model_initializer');
    }
  }

  /// Attempt a single initialization using new FlutterGemma API
  Future<bool> _attemptInitialization(String modelPath) async {
    try {
      developer.log('üîß Installing model via FlutterGemma: $modelPath',
          name: 'dyslexic_ai.model_initializer');

      // Use the new API to install the model from file
      // This registers it as the active model
      await FlutterGemma.installModel(
        modelType: ModelType.gemmaIt,
        fileType: ModelFileType.task, // Default assumption, can expose if needed
      ).fromFile(modelPath).install();
      
      developer.log('‚úÖ Model installed via FlutterGemma',
          name: 'dyslexic_ai.model_initializer');

      // Now ensure we can create an active model session/instance
      developer.log('üöÄ Initializing model for inference...',
          name: 'dyslexic_ai.model_initializer');

      // Log device information for GPU debugging
      if (Platform.isAndroid) {
        developer.log('üì± Platform: Android',
            name: 'dyslexic_ai.model_initializer');
      } else if (Platform.isIOS) {
        developer.log('üì± Platform: iOS',
            name: 'dyslexic_ai.model_initializer');
      }

      final inferenceModel = await _createModelWithFallback();
      if (inferenceModel != null) {
        developer.log('‚úÖ Model initialized successfully for inference',
            name: 'dyslexic_ai.model_initializer');

        // Register the model with the service locator
        final getIt = GetIt.instance;
        if (getIt.isRegistered<InferenceModel>()) {
          getIt.unregister<InferenceModel>();
        }
        getIt.registerSingleton<InferenceModel>(inferenceModel);

        developer.log('‚úÖ Model registered successfully',
            name: 'dyslexic_ai.model_initializer');
        return true;
      } else {
        developer.log('‚ùå Model initialization returned null',
            name: 'dyslexic_ai.model_initializer');
        return false;
      }
    } catch (e) {
      developer.log('‚ùå Error during model initialization: $e',
          name: 'dyslexic_ai.model_initializer');
      return false;
    }
  }

  /// Create model with CPU first, then GPU fallback
  /// Using CPU first because GPU initialization appears to be causing native crashes
  Future<InferenceModel?> _createModelWithFallback() async {
    // Try CPU backend first for stability
    developer.log('üîÑ Attempting CPU backend initialization first (for stability)...',
        name: 'dyslexic_ai.model_initializer');
    
    try {
      // Small delay to allow system resources to stabilize
      await Future.delayed(const Duration(milliseconds: 500));
      
      developer.log('üìä Calling FlutterGemma.getActiveModel with CPU backend...',
          name: 'dyslexic_ai.model_initializer');
          
      final cpuModel = await FlutterGemma.getActiveModel(
        preferredBackend: PreferredBackend.cpu,
        maxTokens: 2048,
        supportImage: true,
        maxNumImages: 1,
      );
      
      developer.log('‚úÖ CPU backend initialized successfully!',
          name: 'dyslexic_ai.model_initializer');
      return cpuModel;
    } catch (cpuError) {
      developer.log('‚ùå CPU backend failed: $cpuError',
          name: 'dyslexic_ai.model_initializer');
    }
    
    // If CPU fails, try GPU as fallback
    developer.log('üîÑ Falling back to GPU backend...',
        name: 'dyslexic_ai.model_initializer');
    
    try {
      // Add delay before GPU initialization to allow memory cleanup
      await Future.delayed(const Duration(seconds: 1));
      
      developer.log('üìä Calling FlutterGemma.getActiveModel with GPU backend...',
          name: 'dyslexic_ai.model_initializer');
          
      final gpuModel = await FlutterGemma.getActiveModel(
        preferredBackend: PreferredBackend.gpu,
        maxTokens: 2048,
        supportImage: true,
        maxNumImages: 1,
      );
      
      developer.log('‚úÖ GPU backend initialized successfully!',
          name: 'dyslexic_ai.model_initializer');
      return gpuModel;
    } catch (gpuError) {
      developer.log('‚ùå GPU backend also failed: $gpuError',
          name: 'dyslexic_ai.model_initializer');
      return null;
    }
  }

  /// Calculate exponential backoff delay with jitter
  Duration _calculateBackoffDelay(int attemptNumber) {
    final exponentialDelay = baseDelay * (1 << (attemptNumber - 1));
    final cappedDelay =
        exponentialDelay > maxDelay ? maxDelay : exponentialDelay;

    // Add small random jitter (¬±20%) to prevent thundering herd
    final jitterMs = (cappedDelay.inMilliseconds *
            0.2 *
            (DateTime.now().millisecondsSinceEpoch % 100) /
            100)
        .round();
    final jitteredDelay = Duration(
        milliseconds: cappedDelay.inMilliseconds +
            jitterMs -
            (cappedDelay.inMilliseconds * 0.1).round());

    return jitteredDelay;
  }

  /// Reset the initializer state (useful for clean retries)
  void reset() {
    _currentAttempt = 0;
    _status = InitializationStatus.notStarted;
    _lastError = null;
    developer.log('üîÑ ModelInitializer reset',
        name: 'dyslexic_ai.model_initializer');
  }
}
